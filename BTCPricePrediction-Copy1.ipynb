{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"/kaggle/input/xau-to-inr-image/Bitcoin_history_price.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Overview\n",
    "\n",
    "    Bitcoin is a decentralized digital currency that can be transferred on the peer-to-peer bitcoin network. Bitcoin transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain. The cryptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto.The currency began use in 2009, when its implementation was released as open-source software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "file_path = 'btc-usd-max.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📒  **<span style='color:#AE08F1'> 1. Load Bitcoin data </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapped_at</th>\n",
       "      <th>price</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>total_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-28 00:00:00 UTC</td>\n",
       "      <td>135.30</td>\n",
       "      <td>1.500518e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-29 00:00:00 UTC</td>\n",
       "      <td>141.96</td>\n",
       "      <td>1.575032e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-30 00:00:00 UTC</td>\n",
       "      <td>135.30</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-01 00:00:00 UTC</td>\n",
       "      <td>117.00</td>\n",
       "      <td>1.298952e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-02 00:00:00 UTC</td>\n",
       "      <td>103.43</td>\n",
       "      <td>1.148668e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                snapped_at   price    market_cap  total_volume\n",
       "0  2013-04-28 00:00:00 UTC  135.30  1.500518e+09           0.0\n",
       "1  2013-04-29 00:00:00 UTC  141.96  1.575032e+09           0.0\n",
       "2  2013-04-30 00:00:00 UTC  135.30  1.501657e+09           0.0\n",
       "3  2013-05-01 00:00:00 UTC  117.00  1.298952e+09           0.0\n",
       "4  2013-05-02 00:00:00 UTC  103.43  1.148668e+09           0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(file_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>total_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4242.000000</td>\n",
       "      <td>4.241000e+03</td>\n",
       "      <td>4.242000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16883.203905</td>\n",
       "      <td>3.207177e+11</td>\n",
       "      <td>1.595336e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20907.654373</td>\n",
       "      <td>4.073053e+11</td>\n",
       "      <td>1.963780e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>67.809000</td>\n",
       "      <td>7.713681e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>612.929000</td>\n",
       "      <td>8.638932e+09</td>\n",
       "      <td>3.355493e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7694.431547</td>\n",
       "      <td>1.352809e+11</td>\n",
       "      <td>6.585688e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27633.566396</td>\n",
       "      <td>5.359673e+11</td>\n",
       "      <td>2.615674e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>101235.371703</td>\n",
       "      <td>2.003239e+12</td>\n",
       "      <td>1.904603e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price    market_cap  total_volume\n",
       "count    4242.000000  4.241000e+03  4.242000e+03\n",
       "mean    16883.203905  3.207177e+11  1.595336e+10\n",
       "std     20907.654373  4.073053e+11  1.963780e+10\n",
       "min        67.809000  7.713681e+08  0.000000e+00\n",
       "25%       612.929000  8.638932e+09  3.355493e+08\n",
       "50%      7694.431547  1.352809e+11  6.585688e+09\n",
       "75%     27633.566396  5.359673e+11  2.615674e+10\n",
       "max    101235.371703  2.003239e+12  1.904603e+11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📊  **<span style='color:#AE08F1'>2. EDA on Bitcoin Data </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'>2.1 Check any null values present </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snapped_at      0\n",
       "price           0\n",
       "market_cap      1\n",
       "total_volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'>2.2 Plotting Few price data </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m start_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m end_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(dataset\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      4\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "start_date = pd.to_datetime(dataset.date[0])\n",
    "end_date = pd.to_datetime(dataset.date.values[-1])\n",
    "dataset['date'] = pd.to_datetime(dataset['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "top_plt = plt.subplot2grid((5,4), (0, 0), rowspan=3, colspan=4)\n",
    "top_plt.plot(dataset.date, dataset[\"price\"])\n",
    "plt.title('Historical stock prices of Bitcoin [01-01-2015 to 20-10-2022]')\n",
    "bottom_plt = plt.subplot2grid((5,4), (3,0), rowspan=1, colspan=4)\n",
    "bottom_plt.bar(dataset.date, dataset['total_volume'])\n",
    "plt.title('\\nBitcoin Trading Volume', y=-0.60)\n",
    "plt.gcf().set_size_inches(16,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'>2.3 Check datatype of Adj Close price </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataset['price'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'>2.4 Find Correlation  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# plotting correlation heatmap\n",
    "plt.figure(figsize = (10, 6))\n",
    "dataplot = sns.heatmap(dataset[['price', 'total_volume', 'market_cap']].corr(), cmap=\"BuPu\", annot=True, \n",
    "                      fmt=\".1f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'>Obs -  </span>** \n",
    "\n",
    "    Here we can observe that, Price and Market_Cap are almost correlate features. \n",
    "    So for Price prediction, we can drop Market_Cap feature. \n",
    "    \n",
    "**Selected Features**\n",
    "\n",
    "* Price\n",
    "* Total Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataset2 = dataset[['price', 'total_volume']]\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'>2.5 Stationarity and detrending (ADF/KPSS)  </span>** \n",
    "\n",
    "Stationarity means that the statistical properties of a time series i.e. mean, variance and covariance do not change over time. Many statistical models require the series to be stationary to make effective and precise predictions.\n",
    "\n",
    "Two statistical tests would be used to check the stationarity of a time series – Augmented Dickey Fuller (“ADF”) test and Kwiatkowski-Phillips-Schmidt-Shin (“KPSS”) test. A method to convert a non-stationary time series into stationary series shall also be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗  **<span style='color:#2980B9'> 2.5.1 - ADF Test  </span>** \n",
    "\n",
    "ADF test is used to determine the presence of unit root in the series, and hence helps in understand if the series is stationary or not. The null and alternate hypothesis of this test are:\n",
    "\n",
    "1. Null Hypothesis: The series has a unit root.\n",
    "2. Alternate Hypothesis: The series has no unit root.\n",
    "\n",
    "**🖊️ If the null hypothesis in failed to be rejected, this test may provide evidence that the series is non-stationary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(dataset2.price.values, autolag='AIC')\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📝 **<span style='color:#2980B9'> 2.5.2 - Let's apply log transformation to the data and test again </span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "\n",
    "result = adfuller((log(dataset2.price.values)), autolag='AIC')\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "for key, value in result[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<div style=\"padding:20px;color:white;margin:0;font-size:250%;text-align:center;display:fill;border-radius:5px;background-color:#C29F10;overflow:hidden;font-weight:700;border: 5px solid #5c74f5;\"> 📈 Predict Bitcoin Future Price 🥇</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📙 **<span style='color:#AE08F1'>3. Time Series Prediction </span>**\n",
    "\n",
    "#### **<span style='color:#2980B9'> 🖌️ We will try to predict the future prices of Bitcoin by using its Price feature. </span>**\n",
    "\n",
    "  **<span style='color:#862DC3'>To perform forecasting, we will need a machine learning model. Most people think of multi-linear regression when they want to predict values. But for Time-series data, this is not a good idea. The main reason to not opt for regression for Time-Series Data is we are interested in predicting the future, which would be extrapolation (predicting outside the range of the data) for linear regression. And as we know that in linear regression any sort of extrapolation is not advisable. </span>**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📗 **<span style='color:#2980B9'>What Model to Use?  </span>**\n",
    "\n",
    "📜  **<span style='color:#2980B9'>ARIMA  </span>**\n",
    "    \n",
    "📜  **<span style='color:#2980B9'>NEURAL NETWORK  </span>**\n",
    "    \n",
    "📜  **<span style='color:#2980B9'>RECURRENT NEURAL NETWORK  </span>**\n",
    "    \n",
    "📜  **<span style='color:#2980B9'>LSTM - LONG SHORT TERM MEMORY  </span>**\n",
    "    \n",
    "📜  **<span style='color:#2980B9'>CNN - CONVOLUTION NEURAL NETWORK  </span>**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📙 **<span style='color:#AE08F1'>4. ARIMA - Univariate Price Forecasting  </span>**\n",
    "\n",
    "    ARIMA is a class of models that ‘explains’ a given time series based on its own past values, i.e, its own lags and the lagged forecast errors, so that equation can be used to forecast future values. Any ‘non-seasonal’ time series that exhibits patterns and is not a random white noise can be modeled with ARIMA models. The hypothesis testing (ADF) performed priorly, showed the prices were not stationary, hence we can not use an ARIMA model. We can use Neural networks for price predictions. \n",
    "\n",
    "#### **<span style='color:#2980B9'> Let's check how ARIMA works here  </span>** \n",
    "\n",
    "    To create an ARIMA model, we need 3 parameters:\n",
    "\n",
    "* p; the order of the Auto-Regressive term\n",
    "* q; the order of the Moving Average term\n",
    "* d; the number of differencing required to make the time-series stationary\n",
    "\n",
    "#### **<span style='color:#2980B9'> Determining Stationarity  </span>**  \n",
    "    \n",
    "    We will need the time-series data to be stationary because, the term Auto Regressive in ARIMA means it is a linear regression model that uses its own lags as predictors. Linear regression models, as you know, work best when the predictors are not correlated and are independent of each other.\n",
    "    \n",
    "    To achieve Stationarity, we need to perform differencing: subtract the previous value from the current value. Sometimes, depending on the complexity of the series, more than one differencing may be needed. Before we do this, we need to check if our data already is stationary or not. For this we will use the Augmented Dickey Fuller test. This is a Hypothesis test, assuming the Null hypothesis to be “A unit root is present in an Autoregressive model”. Unit Root tests whether a time series variable is non-stationary and possesses a unit root. If a series has a unit root, its shows a systematic pattern. The Alternate Hypothesis, in this case, will be that “No unit root is present”, which means the time series is stationary.\n",
    "    \n",
    "* Data is not stationary, we can use differencing 2 times. \n",
    "\n",
    "####  **<span style='color:#2980B9'> Determining the order of the AR term  </span>**   \n",
    "\n",
    "    p is the order of the Auto Regressive (AR) term. It refers to the number of lags of Y to be used as predictors. We can find out the required number of AR terms by inspecting the Partial Autocorrelation Function(PACF) plot. Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## **<span style='color:#2980B9'>4.1 - ARIMA model in words:  </span>** \n",
    "\n",
    "    Predicted Yt = Constant + Linear combination Lags of Y (upto p lags) + Linear Combination of Lagged forecast errors (upto q lags)\n",
    "\n",
    "    The objective, therefore, is to identify the values of p, d and q. But how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "# Original Series\n",
    "fig, axes = plt.subplots(3, 2, sharex=True)\n",
    "axes[0, 0].plot(dataset2['price'].values); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(dataset2['price'].values, ax=axes[0, 1])\n",
    "\n",
    "# 1st Differencing\n",
    "axes[1, 0].plot(dataset2['price'].diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(dataset2['price'].diff().dropna(), ax=axes[1, 1])\n",
    "\n",
    "# 2nd Differencing\n",
    "axes[2, 0].plot(dataset2['price'].diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\n",
    "plot_acf(dataset2['price'].diff().diff().dropna(), ax=axes[2, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(10,5))\n",
    "plot_acf(dataset2['price'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(10,5))\n",
    "plot_pacf(dataset2['price'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "We can observe that the PACF lag 2 is the only one that is quite significant and it is well above the significance line compared to other values. Hence, we can safely set p to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# PACF plot of 1st differenced series\n",
    "plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=True)\n",
    "axes[0].plot(dataset2['price'].diff()); axes[0].set_title('1st Differencing')\n",
    "axes[1].set(ylim=(0,5))\n",
    "plot_pacf(dataset2['price'].diff().dropna(), ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'> 4.2 - Determining the order of the MA term  </span>** \n",
    "\n",
    "    q is the order of the Moving Average (MA) term. It refers to the number of lagged forecast errors that should go into the ARIMA Model. An MA term is technically, the error of the lagged forecast.\n",
    "    \n",
    "    Just like how we looked at the PACF plot for the number of AR terms, you can look at the ACF plot for the number of MA terms. The ACF tells how many MA terms are required to remove any autocorrelation in the stationarized series.\n",
    "    \n",
    "    Count the number of lags that are well above the significance line. So, let’s tentatively fix q as 8.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True)\n",
    "axes[0].plot(dataset2['price'].diff()); axes[0].set_title('1st Differencing')\n",
    "axes[1].set(ylim=(0,1.2))\n",
    "plot_acf(dataset2['price'].diff().dropna(), ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "data = dataset2['price'].values\n",
    "print('Length of Total data: ', len(data))\n",
    "train_length = int(len(data) * 0.8)\n",
    "train_data = data[:train_length]\n",
    "test_data = data[train_length:]\n",
    "print('Train and Test data length: ', len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'> 4.3 - Building ARIMA Model  </span>**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "model = ARIMA(train_data, order=(1,0,8))\n",
    "model_fit = model.fit(low_memory = False)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Plot residual errors\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "forecast_result = model_fit.forecast(150, alpha=0.05)  # 95% conf\n",
    "forecast_result[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "test_data[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#2980B9'> 4.4 - Plot Test and Predicted Results  </span>**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Here we're plotting Test and Predicted data\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.plot(test_data[:150], '#0077be',label = 'Actual')\n",
    "plt.plot(forecast_result[:], '#ff8841',label = 'Predicted')\n",
    "plt.title('ARIMA Model for BITCOIN Price Forecasting')\n",
    "plt.ylabel('BITCOIN Price [in Dollar]')\n",
    "plt.xlabel('Time Steps [in Days] ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> Overview of ANN -  </span>**\n",
    "Artificial Neural Networks (ANN) are multi-layer fully-connected neural nets that look like the figure below. They consist of an input layer, multiple hidden layers, and an output layer. Every node in one layer is connected to every other node in the next layer. We make the network deeper by increasing the number of hidden layers.\n",
    "\n",
    "![](https://miro.medium.com/max/720/1*Gh5PS4R_A5drl5ebd_gNrg@2x.png)\n",
    "\n",
    "    If we zoom in to one of the hidden or output nodes, what we will encounter is the figure below.\n",
    "    \n",
    "![](https://miro.medium.com/max/720/1*FcEfcrucAFymCr0gMFQ0QA@2x.png)   \n",
    "\n",
    "A given node takes the weighted sum of its inputs, and passes it through a non-linear activation function. This is the output of the node, which then becomes the input of another node in the next layer. The signal flows from left to right, and the final output is calculated by performing this procedure for all the nodes. Training this deep neural network means learning the weights associated with all the edges.\n",
    "\n",
    "The equation for a given node looks as follows. The weighted sum of its inputs passed through a non-linear activation function. It can be represented as a vector dot product, where n is the number of inputs for the node.\n",
    "\n",
    "![](https://miro.medium.com/max/720/1*XBGeSr4IkHql0ZG_QnQu-Q@2x.png)\n",
    "\n",
    "Backpropagation with gradient descent is literally the “magic” behind the deep learning models. It’s a rather long topic and involves some calculus, so we won’t go into the specifics in this applied deep learning series. \n",
    "\n",
    "**Common activation functions**\n",
    "\n",
    "An activation function determines whether a neuron should be activated. The nonlinear functions typically convert the output of a given neuron to a value between 0 and 1 or -1 and 1. Some of the most commonly used functions are defined as follows:\n",
    "\n",
    "**Sigmoid**: This is represented with the formula g(x) = 1/(1 + e^-x).\n",
    "\n",
    "![](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_13H-RecurrentNeuralNetworks-WHITEBG.png)\n",
    "\n",
    "**Tanh**: This is represented with the formula g(x) = (e^-x - e^-x)/(e^-x + e^-x).\n",
    "\n",
    "![](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_13I-RecurrentNeuralNetworks-WHITEBG.png)\n",
    "\n",
    "**Relu**: This is represented with the formula g(x) = max(0 , x)\n",
    "\n",
    "![](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_13J-RecurrentNeuralNetworks-WHITEBG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📙 **<span style='color:#AE08F1'> 5. Artificial Neural Network - Bitcoin price forecasting  </span>**\n",
    "\n",
    "**Univariate Stock price forecasting**\n",
    "\n",
    "    Using price data, we'll forecast the stock price for the next day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.1 Load Data - \"price\" data  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "data = dataset2['price'].values\n",
    "print('Shape of data: ', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.2 Separate Train and Test data  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Separate train and test data\n",
    "train_length = int(len(data) * 0.8)\n",
    "print('Train length: ', train_length)\n",
    "\n",
    "train_data, test_data = data[:train_length], data[train_length:]\n",
    "print('Shape of Train and Test data: ', train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.3 Change Shape - Need 2D data  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.reshape(-1, 1)\n",
    "test_data = test_data.reshape(-1, 1)\n",
    "print('Shape of Train and Test data: ', train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.4 Split a Univariate sequence to Supervised Learning  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into supervised learning [Input and Output]\n",
    "def create_dataset(dataset, lookback):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - lookback -1):\n",
    "        a = dataset[i: (i+lookback), 0]\n",
    "        dataX.append(a)\n",
    "        b = dataset[i+lookback, 0]\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.5 Automatically select Lag value from PACF graph  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot_pacf(data, lags=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.6 Taking Auto-correlation Lag value Greater than 10%  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "pacf_value = pacf(data, nlags=20)\n",
    "lag = 0\n",
    "# collect lag values greater than 10% correlation \n",
    "for x in pacf_value:\n",
    "    if x > 0.1:\n",
    "        lag += 1\n",
    "    else:\n",
    "        break\n",
    "print('Selected look_back (or lag = ): ', lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.7 Separate Input and Output  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_X, train_y = create_dataset(train_data, lag)\n",
    "test_X, test_y = create_dataset(test_data, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('Shape of train_X and train_y: ', train_X.shape, train_y.shape)\n",
    "print('Shape of test_X and test_y: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.8 How Data Looks Like - Input and Output  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(train_data[:20])            # original data\n",
    "for x in range(len(train_X[:20])):\n",
    "    print(test_X[x], test_y[x], )            # trainX and trainY after lookback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.9 Build an MLP model  </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "* **<span style='color:#862DC3'>Sequential()** </span> <span style='color:#108693'> - The sequential API allows you to create models layer-by-layer </span>\n",
    "\n",
    "* **<span style='color:#862DC3'>add()** </span> <span style='color:#108693'> - To create a Sequential model incrementally via the add() method </span>\n",
    "\n",
    "* **<span style='color:#862DC3'>Dense()** </span> <span style='color:#108693'> - To add a stack of fully connected layer (either a hidden layer or an output layer) </span>\n",
    "\n",
    "* **<span style='color:#862DC3'>input_dim** </span>  <span style='color:#108693'> - To specify the input shape </span>\n",
    "\n",
    "* **<span style='color:#862DC3'>Activation** </span> <span style='color:#108693'> - Decides the output a node. The purpose of the activation function is to introduce non-linearity into the output of a neuron. </span>\n",
    "\n",
    "* **<span style='color:#862DC3'>Loss Function** </span> <span style='color:#108693'> - The function we want to minimize or maximize is called the objective function or criterion. When we are minimizing it, we may also call it the cost function, loss function, or error function. </span>\n",
    "\n",
    "* **<span style='color:#862DC3'>Optimizer** </span> <span style='color:#108693'> - Minimizing the loss function, by changing the parameters (weights and biases) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "# Thes seed value helps in initilizing random weights and biases to the neural network.  \n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ML libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = lag, activation='relu', name= \"1st_hidden\"))\n",
    "# model.add(Dense(64, activation='relu', name = '2nd_hidden'))\n",
    "model.add(Dense(1, name = 'Output_layer', activation='linear'))\n",
    "# model.add(Activation(\"linear\", name = 'Linear_activation'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📗 **<span style='color:#AE08F1'> 5.10 Fit data to Model  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "epoch_number = 100\n",
    "batches = 64\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs = epoch_number, batch_size = batches, verbose = 1, shuffle=False, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📗 **<span style='color:#AE08F1'> 5.11 Train and Validation Loss  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.clf\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Train and Test Loss')\n",
    "plt.title('Train and Test loss per epochs [Univariate]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.12 Make Prediction  </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "testPredict = model.predict(test_X)\n",
    "predicted_value = testPredict[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 **<span style='color:#AE08F1'> 5.13 Evaluation Metrics to Measure Performance  </span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> R-Squared </span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Mean Absolute Error </span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Mean Absolute Percentage Error</span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Mean Squared Error</span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Root Mean Squared Error</span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Normalized Root Mean Squared Error</span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Weighted Absolute Percentage Error</span>**\n",
    "\n",
    "* **<span style='color:#0A7681'> Weighted Mean Absolute Percentage Error</span>**\n",
    "\n",
    "Ref: https://analyticsindiamag.com/a-guide-to-different-evaluation-metrics-for-time-series-forecasting-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_forecast_results(actual, predicted):\n",
    "    print('R2 Score: ', round(r2_score(actual, predicted), 2))\n",
    "    print('MAE : ', round(mae(actual, predicted), 2))\n",
    "    print('MSE: ', round(mean_squared_error(actual,predicted), 2))\n",
    "    print('RMSE: ', round(math.sqrt(mean_squared_error(actual,predicted)), 2))\n",
    "    print('NRMSE: ', NRMSE(actual, predicted))\n",
    "    print('WMAPE: ', WMAPE(actual, predicted))\n",
    "    \n",
    "def NRMSE(actual, predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(actual,predicted))\n",
    "    nrmse = rmse / np.mean(actual)\n",
    "    return round(nrmse, 4)\n",
    "\n",
    "def WMAPE(actual, predicted):\n",
    "    abs_error = np.sum(actual - predicted)\n",
    "    wmape = abs_error / np.sum(actual)\n",
    "    return round(wmape, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "evaluate_forecast_results(test_y, predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Here we're plotting Test and Predicted data\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.plot(test_y[:], '#0077be',label = 'Actual')\n",
    "plt.plot(predicted_value, '#ff8841',label = 'Predicted')\n",
    "plt.title('MLP Model for BITCOIN Price Forecasting')\n",
    "plt.ylabel('BITCOIN Price [in Dollar]')\n",
    "plt.xlabel('Time Steps [in Days] ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "A recurrent neural network (RNN) is a type of artificial neural network which uses sequential data or time series data. These deep learning algorithms are commonly used for ordinal or temporal problems, such as language translation, natural language processing (nlp), speech recognition, and image captioning; they are incorporated into popular applications such as Siri, voice search, and Google Translate.\n",
    "\n",
    "Like feedforward and convolutional neural networks (CNNs), recurrent neural networks utilize training data to learn. They are distinguished by their “memory” as they take information from prior inputs to influence the current input and output. While traditional deep neural networks assume that inputs and outputs are independent of each other, the output of recurrent neural networks depend on the prior elements within the sequence. \n",
    "\n",
    "**Recurrent Neural Network vs. Feedforward Neural Network**\n",
    "\n",
    "![](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_13A-RecurrentNeuralNetworks-WHITEBG.png)\n",
    "\n",
    "![](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_13B-RecurrentNeuralNetworks-WHITEBG.png)\n",
    "\n",
    "**Backpropagation through time (BPTT)**\n",
    "\n",
    "Recurrent neural networks leverage backpropagation through time (BPTT) algorithm to determine the gradients, which is slightly different from traditional backpropagation as it is specific to sequence data. The principles of BPTT are the same as traditional backpropagation, where the model trains itself by calculating errors from its output layer to its input layer. \n",
    "\n",
    "These calculations allow us to adjust and fit the parameters of the model appropriately. BPTT differs from the traditional approach in that BPTT sums errors at each time step whereas feedforward networks do not need to sum errors as they do not share parameters across each layer.\n",
    "\n",
    "**Vanishing gradients and Exploding gradients Problems**\n",
    "\n",
    "RNNs tend to run into two problems, known as exploding gradients and vanishing gradients. These issues are defined by the size of the gradient, which is the slope of the loss function along the error curve. \n",
    "\n",
    "When the gradient is too small, it continues to become smaller, updating the weight parameters until they become insignificant—i.e. 0. When that occurs, the algorithm is no longer learning. \n",
    "\n",
    "Exploding gradients occur when the gradient is too large, creating an unstable model. In this case, the model weights will grow too large, and they will eventually be represented as NaN. One solution to these issues is to reduce the number of hidden layers within the neural network, eliminating some of the complexity in the RNN model.\n",
    "\n",
    "![](https://stanford.edu/~shervine/teaching/cs-230/illustrations/architecture-rnn-ltr.png?9ea4417fc145b9346a3e288801dbdfdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# 📒 6. RNN - Univariate Time Series Forecasting\n",
    "\n",
    "## 📗 6.1 Load Data - \"Adj Close\" price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "data = dataset2['price'].values\n",
    "print('Shape of data: ', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.2 Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Separate train and test data\n",
    "train_length = int(len(data) * 0.8)\n",
    "print('Train length: ', train_length)\n",
    "\n",
    "train_data, test_data = data[:train_length], data[train_length:]\n",
    "print('Shape of Train and Test data: ', len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.3 Make time-series data supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into supervised learning [Input and Output]\n",
    "from numpy import array\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.4 Lag Value already Choosen from PACF Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "pacf_value = pacf(data, nlags=20)\n",
    "lag = 0\n",
    "# collect lag values greater than 10% correlation \n",
    "for x in pacf_value:\n",
    "    if x > 0.1:\n",
    "        lag += 1\n",
    "    else:\n",
    "        break\n",
    "print('Selected look_back (or lag = ): ', lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data, lag)\n",
    "test_X, test_y = split_sequence(test_data, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('Shape of train_X and train_y: ', train_X.shape, train_y.shape)\n",
    "print('Shape of test_X and test_y: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.5 Reshape train_X and test_X to 3-Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# New shape of train_X and test_X are :-\n",
    "print('Shape of train_X and train_y: ', train_X.shape, train_y.shape)\n",
    "print('Shape of test_X and test_y: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.6 Building and Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, activation='relu', return_sequences=False, input_shape=(lag, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.7 Fit the model - with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# As you are trying to use function decorator in TF 2.0, \n",
    "# please enable run function eagerly by using below line after importing TensorFlow:\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Callbacks API\n",
    "\n",
    "A callback is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc).\n",
    "\n",
    "You can use callbacks to:\n",
    "\n",
    "* Write TensorBoard logs after every batch of training to monitor your metrics\n",
    "* Periodically save your model to disk\n",
    "* Do early stopping\n",
    "* Get a view on internal states and statistics of a model during training\n",
    "\n",
    "Ref: https://keras.io/api/callbacks/#:~:text=A%20callback%20is%20an%20object,Do%20early%20stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n",
    "history = model.fit(train_X, train_y, epochs = 150, batch_size=64, verbose=1, validation_split= 0.1, \n",
    "                   callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.8 Summarize model accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.9 Make prediction - with Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_predict = model.predict(train_X)\n",
    "test_predict = model.predict(test_X)\n",
    "\n",
    "print('Shape of train and test predict: ', train_predict.shape, test_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 6.10 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "actual_ = test_y\n",
    "predicted_ = test_predict[:, 0]\n",
    "len(actual_), len(predicted_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "evaluate_forecast_results(actual_, predicted_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 6.11 Plot test data and Predicted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(14,8))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.plot(actual_, label = 'Actual')\n",
    "plt.plot(predicted_, label = 'Predicted')\n",
    "plt.xlabel('Time in days')\n",
    "plt.ylabel('BITCOIN price')\n",
    "plt.title('BITCOIN price prediction using Simple RNN - Test data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns = ['Train data'])\n",
    "df_train['Train data'] = train_data\n",
    "\n",
    "df = pd.DataFrame(columns = ['Test data', 'Predicted data'])\n",
    "df['Test data'] = actual_\n",
    "df['Predicted data'] = predicted_\n",
    "\n",
    "total_len = len(df_train['Train data']) + len(df['Test data'])\n",
    "range(len(df_train['Train data']), total_len)\n",
    "x_list = [x for x in range(len(df_train['Train data']), total_len)]\n",
    "df.index = x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(14,8))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.xlabel('Time in days')\n",
    "plt.ylabel('BITCOIN price')\n",
    "plt.title('BITCOIN price prediction using Simple RNN')\n",
    "plt.plot(df_train['Train data'])\n",
    "plt.plot(df[['Test data', 'Predicted data']])\n",
    "plt.legend(['Train', 'Test', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "data = dataset2['price'].values\n",
    "print('Shape of data: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Separate train and test data\n",
    "train_length = int(len(data) * 0.8)\n",
    "print('Train length: ', train_length)\n",
    "train_data, test_data = data[:train_length], data[train_length:]\n",
    "print('Shape of Train and Test data: ', len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 7.3 Make univariate-series as Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# split a univariate sequence into supervised learning [Input and Output]\n",
    "from numpy import array\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 4.4 Choose Lag value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "lag = 2  # Already this is calculated in 5.4 and 6.4 \n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_X, train_y = split_sequence(train_data, lag)\n",
    "test_X, test_y = split_sequence(test_data, lag)\n",
    "\n",
    "print('Shape of train_X and train_y: ', train_X.shape, train_y.shape)\n",
    "print('Shape of test_X and test_y: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 4.5 Reshape train_X and test_X to 3-Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_features))\n",
    "\n",
    "# New shape of train_X and test_X are :-\n",
    "print('Shape of train_X and train_y: ', train_X.shape, train_y.shape)\n",
    "print('Shape of test_X and test_y: ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 5. Building a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 5.1 Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True, input_shape=(lag, n_features)))\n",
    "model.add(LSTM(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 5.2 Fit model with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# As you are trying to use function decorator in TF 2.0, \n",
    "# please enable run function eagerly by using below line after importing TensorFlow:\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n",
    "history = model.fit(train_X, train_y, epochs = 150, batch_size = 64, verbose=1, validation_split= 0.1, \n",
    "                   callbacks = [cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 5.3 Summarize model accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 5.4 Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "train_predict = model.predict(train_X)\n",
    "test_predict = model.predict(test_X)\n",
    "\n",
    "print('Shape of train and test predict: ', train_predict.shape, test_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 📗 5.5 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "actual_lstm = test_y\n",
    "predicted_lstm = test_predict[:, 0]\n",
    "evaluate_forecast_results(actual_lstm, predicted_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns = ['Train data'])\n",
    "df_train['Train data'] = train_data\n",
    "\n",
    "df = pd.DataFrame(columns = ['Test data', 'Predicted data'])\n",
    "df['Test data'] = actual_lstm\n",
    "df['Predicted data'] = predicted_lstm\n",
    "\n",
    "total_len = len(df_train['Train data']) + len(df['Test data'])\n",
    "range(len(df_train['Train data']), total_len)\n",
    "x_list = [x for x in range(len(df_train['Train data']), total_len)]\n",
    "df.index = x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(14,8))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.xlabel('Time in days')\n",
    "plt.ylabel('BITCOIN price')\n",
    "plt.title('BITCOIN price prediction using LSTM')\n",
    "plt.plot(df_train['Train data'])\n",
    "plt.plot(df[['Test data', 'Predicted data']])\n",
    "plt.legend(['Train', 'Test', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2475432,
     "sourceId": 4552545,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2499268,
     "sourceId": 7953498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30260,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
